{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will's cone detection notebook\n",
    "\n",
    "## Purpose\n",
    "\n",
    "I'm not very good at java tbh, so I'll do my code things here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from math import ceil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from num2words import num2words\n",
    "\n",
    "# grab relative path for loading images\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"Notebook.ipynb\")\n",
    "\n",
    "def compose(*f_arg_pairs):\n",
    "    def cr(*fs):\n",
    "        pair = fs[0]\n",
    "        if len(fs) == 1:\n",
    "            return lambda x:pair[0](x,*pair[1])\n",
    "        return lambda x:pair[0](cr(*fs[1:])(x),*pair[1])\n",
    "    return cr(*reversed(f_arg_pairs))\n",
    "\n",
    "def compose_gen(*f_arg_pairs):\n",
    "    def cr(arg):\n",
    "        pairs = [arg]\n",
    "        for f_arg in f_arg_pairs:\n",
    "            pairs.append(f_arg[0](pairs[-1], *f_arg[1]))\n",
    "        return pairs\n",
    "    return cr\n",
    "\n",
    "digitalsum = compose(\n",
    "    (int,()),\n",
    "    (str,()),\n",
    "    (list,()),\n",
    "    (lambda x: (int(n) for n in x),()),\n",
    "    (sum, ()),\n",
    ")\n",
    "\n",
    "# print(digitalsum(314159265358979323))\n",
    "\n",
    "\n",
    "def add_image(*dispImage):\n",
    "    wrap = 4\n",
    "    if len(dispImage) > wrap: #wrap is the maximum amount of pictures before they get too small to see.\n",
    "        x,y = wrap,ceil(len(dispImage)/wrap)\n",
    "    else:\n",
    "        x,y = len(dispImage),1\n",
    "    fig = plt.figure(figsize=(6*x,8*y))\n",
    "    for index, img in enumerate(dispImage):\n",
    "        fig.add_subplot(y, x, index+1)\n",
    "        # showing image\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(num2words(index+1,True,to=\"ordinal\").capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flood_from_pix(floodImg: np.ndarray, pixel: tuple = ()):\n",
    "    h, w = floodImg.shape[:2]\n",
    "    if not pixel: pixel = (w//2, h//2)\n",
    "    mask = np.zeros((h+2,w+2), np.uint8)\n",
    "    flat = floodImg.astype(\"uint8\")\n",
    "    cv2.floodFill(flat, mask, pixel, 255)\n",
    "    return cv2.threshold(flat, 254, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "def resize_image(dimImage: np.ndarray, newsize: tuple = ()):\n",
    "    print(dims:=dimImage.shape)\n",
    "    if newsize:\n",
    "        rowedge = (dims[0]-newsize[0])//2\n",
    "        coledge = (dims[1]-newsize[1])//2\n",
    "        return dimImage[rowedge:dims[0]-rowedge,coledge:dims[1]-coledge]\n",
    "\n",
    "    return dimImage\n",
    "\n",
    "def tri_stack(stackImg: np.ndarray):\n",
    "    return np.dstack([stackImg,stackImg,stackImg])\n",
    "\n",
    "def extract_channel(extrImg: np.ndarray, channel: int = 0):\n",
    "    return tri_stack(extrImg[:,:,channel])\n",
    "\n",
    "def point(pointImg: np.ndarray, xy: tuple, clr: tuple):\n",
    "    return cv2.circle(pointImg, xy, radius=5, color=clr, thickness=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Pipeline\n",
    "\n",
    "This pipeline takes a cone with a shape on it, and returns a mask over the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "color_pipeline = lambda img, seed: compose_gen(\n",
    "        (extract_channel, (0,)),\n",
    "        # 200 is min, 250 is max. If theres too much bg noise, turn up 200. If the shape gets cut, turn down 250.\n",
    "        (cv2.Canny, (400, 500)),\n",
    "        (cv2.blur, ((5, 5),)),\n",
    "        (flood_from_pix, (seed,)),\n",
    "        # (cv2.Canny, (200, 250)),\n",
    "        # (lambda x: cv2.threshold(x,254,255,cv2.THRESH_BINARY)[1],()),\n",
    "        # (cv2.blur, ((5, 5),)),\n",
    "        # (tri_stack, ()),\n",
    "        # (point, (seed, (255,0,0))),\n",
    "        (np.ndarray.astype,(\"uint8\",)),\n",
    "    )(img)\n",
    "\n",
    "image = cv2.imread(\"Images/Shapes/Downscaled/trianglepb_downscaled_cone.jpg\")\n",
    "# webcam = cv2.VideoCapture(0)\n",
    "# image = webcam.read()[1]\n",
    "# webcam.release()\n",
    "width, height, depth = image.shape\n",
    "\n",
    "prep_pipeline = compose(\n",
    "    (cv2.flip, (1,)),\n",
    "    (cv2.cvtColor, (cv2.COLOR_RGB2BGR,)),\n",
    "    # (resize_image, ((480,360),)),\n",
    ")\n",
    "\n",
    "image = prep_pipeline(image)\n",
    "\n",
    "cnvimage = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "# cnvimages = color_pipeline(image,(250,245))\n",
    "cnvimages = color_pipeline(image,(251,253))\n",
    "# cnvimage = cv2.cvtColor(cnvimage, cv2.COLOR_HSV2RGB)\n",
    "# add_image(cnvimages[5])\n",
    "add_image(*cnvimages)\n",
    "# cnvimage = cv2.cvtColor(cnvimage, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "# cv2.imwrite(\"Images/Shapes V2/Normal/Pentagon.png\",image)\n",
    "# cv2.imwrite(\"Images/Shapes V2/Processed/Pentagon.png\",cnvimage)\n",
    "\n",
    "dump(image, open(\"temp/wimage\",'wb+'))\n",
    "dump(cnvimages[-1], open(\"temp/cnvimage\",'wb+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab edges\n",
    "\n",
    "Take the edges, find the contours, and then approximate as a polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "# image = load(open(\"temp/image\",'rb'))\n",
    "image = load(open(\"temp/wimage\",'rb'))\n",
    "cnvimage = load(open(\"temp/cnvimage\",'rb'))\n",
    "# cvnimage = cnvimages[-1]\n",
    "\n",
    "    # contours, _ = cv2.findContours(made_im, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # return cv2.approxPolyDP(contours[contour],20,True),made_im\n",
    "\n",
    "# poly, outimage = count_poly_seed((height//2,width//2))\n",
    "\n",
    "polys = []\n",
    "for contour in cv2.findContours(cnvimage, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]:\n",
    "    # contour = contour[0]\n",
    "    if len(contour) <= 10: continue\n",
    "    if len(poly:=cv2.approxPolyDP(contour,20,True)) > 1:\n",
    "        polys.append(poly)\n",
    "\n",
    "# poly, outimage = count_poly_seed((height//2,width//2))\n",
    "\n",
    "# approxpolydp PER contour, filter out 1's\n",
    "cnv_draws = []\n",
    "for poly in polys:\n",
    "    cnv_draw = np.zeros(cnvimage.shape,dtype=np.uint8)\n",
    "    cnv_draw = tri_stack(cnv_draw)\n",
    "    cnv_draw = cv2.polylines(cnv_draw,[poly],True,(0,0,255),3)\n",
    "    # cnv_draw = cv2.drawContours(cnv_draw,poly,-1,(0,0,255),3)\n",
    "    cnv_draws.append(cnv_draw)\n",
    "\n",
    "cnvimage = tri_stack(cnvimage)\n",
    "cnvimage = cv2.drawContours(cnvimage,polys,-1,(0,255,0),5)\n",
    "\n",
    "# add_image(cnv_draws[1])\n",
    "add_image(image, cnvimage, *cnv_draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get middle pixel\n",
    "This will get the middle pixel location, from there we can do an additional color analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = polys[0]\n",
    "\n",
    "def average_pix(polycontour: np.ndarray):\n",
    "    return tuple(sum(polycontour[:,:,x])[0]//len(polycontour) for x in (0,1))\n",
    "\n",
    "print(*average_pix(poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "I will combine all of the previous cells into one big pipeline that should, in theory, detect shapes on cones in a robust way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def get_shape(input_image: np.ndarray):\n",
    "    '''Takes an input image, and tries to \\\n",
    "       return the number of sides in a \\\n",
    "       detected polygon. If this fails, \\\n",
    "       `return None`. `input_image` is in \\\n",
    "       HSV.'''\n",
    "    \n",
    "    # Variables used throughout the pipeline.\n",
    "    im_h, im_w, _ = input_image.shape\n",
    "\n",
    "    fill_pipe = lambda img, seed: compose_gen(\n",
    "        (extract_channel, (2,)),\n",
    "        # 400 is min, 500 is max. If theres too much bg noise, turn up 400. If the shape gets cut, turn down 500.\n",
    "        (cv2.Canny, (200, 200)),\n",
    "        (cv2.blur, ((5, 5),)),\n",
    "        (flood_from_pix, (seed,)),\n",
    "        (np.ndarray.astype,(\"uint8\",)),\n",
    "    )(img)\n",
    "\n",
    "    pipe_b = lambda img, shape: compose_gen(\n",
    "        (point, (new_seed,(255,0,0))),\n",
    "        (cv2.polylines, [polys[0]],True,(0,0,255,3)),\n",
    "    )\n",
    "\n",
    "    full_pipe = fill_pipe(input_image,(im_w//2,im_h//2))\\\n",
    "\n",
    "    cnvimage = full_pipe[-1]\n",
    "\n",
    "    def get_polys(poly_image: np.ndarray):\n",
    "        polys = []\n",
    "        for contour in cv2.findContours(poly_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]:\n",
    "            # if len(contour) <= 10: continue\n",
    "            if len(poly:=cv2.approxPolyDP(contour,20,True)) > 1:\n",
    "                polys.append(poly)\n",
    "        return polys\n",
    "    \n",
    "    polys = get_polys(cnvimage)\n",
    "    \n",
    "    # distance formula\n",
    "    def dst_from_center(x,y):\n",
    "        return sqrt((x1:=x-im_w//2)*x1 + (y1:=y-im_h//2)*y1)\n",
    "\n",
    "    # Per shape, get average point distance to the center\n",
    "    avg_dists = [sum(dst_from_center(x,y) for x,y in poly[:,0])/len(poly) for poly in polys]\n",
    "\n",
    "    # with the index of the minimum shape, get the average pixel\n",
    "    new_seed = average_pix(polys[avg_dists.index(min(avg_dists))])\n",
    "\n",
    "    print(new_seed)\n",
    "    \n",
    "    cnvimage = tri_stack(cnvimage)\n",
    "    cnvimages = fill_pipe(cnvimage,new_seed)\n",
    "\n",
    "    polys = get_polys(cnvimages[-1])\n",
    "    # Image is ready\n",
    "    return len(polys[0]),full_pipe,cnvimages,new_seed\n",
    "\n",
    "# image = cv2.imread(\"Images/Shapes/Downscaled/squarebb_downscaled_cone.jpg\")\n",
    "image = load(open(\"temp/wimage\",'rb'))\n",
    "# webcam = cv2.VideoCapture(0)\n",
    "# image = webcam.read()[1]\n",
    "# webcam.release()\n",
    "\n",
    "# dump(image, open(\"temp/wimage\",'wb+'))\n",
    "\n",
    "\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "prep_pipeline = compose(\n",
    "    (resize_image, ((480,360),)),\n",
    "    (cv2.flip, (1,)),\n",
    "    (cv2.cvtColor, (cv2.COLOR_RGB2HSV,)),\n",
    ")\n",
    "\n",
    "# add_image(image)\n",
    "# point(cv2.flip(image,1),d,clr=(255,0,0))\n",
    "a, b, c, d = get_shape(prep_pipeline(image))\n",
    "print(a,image.shape)\n",
    "add_image(image)\n",
    "add_image(*b,*c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QR codes\n",
    "\n",
    "I may be a fool, if this works I will cry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrScanner = cv2.QRCodeDetector()\n",
    "image = cv2.imread(\"Images/QR/coneqr1.jpg\")\n",
    "print(qrScanner.detectAndDecode(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8563a19876151bfb06a7c3bb50edebffd13ce42d1aa9242116825cc867e2cb67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
